{"meta":{"title":"Hexo","subtitle":"","description":"","author":"John Doe","url":"http://example.com","root":"/"},"pages":[{"title":"Categories","date":"2022-05-22T06:06:58.959Z","updated":"2022-05-22T06:06:58.959Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"About","date":"2022-05-22T06:06:58.956Z","updated":"2022-05-22T06:06:58.956Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":""},{"title":"Tags","date":"2022-05-22T06:06:58.966Z","updated":"2022-05-22T06:06:58.966Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Spark流程配置","slug":"Spark流程配置","date":"2022-05-28T07:57:22.000Z","updated":"2022-05-28T08:18:09.653Z","comments":true,"path":"2022/05/28/Spark流程配置/","link":"","permalink":"http://example.com/2022/05/28/Spark%E6%B5%81%E7%A8%8B%E9%85%8D%E7%BD%AE/","excerpt":"","text":"五、Spark(local)模式Spark（local）本地模式是以一个独立的进程，通过其内部的多个线程来模拟整个Spark运行时的环境Spark由四类角色组成整个Spark的运行环境●Master角色，管理整个集群的资源●Worker角色，管理单个服务器的资源●Driver角色，管理单个Spark任务在运行的时候的工作●Executor角色，单个任务运行的时候的工作者 Anaconda On Linux 安装（1）上传Anaconda3-2021.05-Linux-x86_64.sh文件到虚拟机&#x2F;export&#x2F;server&#x2F;目录下；使用cd命令进入到&#x2F;export&#x2F;server&#x2F;下，随后sh执行Anaconda3-2021.05-Linux-x86_64.sh 在遇到Do you accept the license terms? [yes | no]时，选择yes （2）在上述命令回车后，会让你选择你想要安装的路径，统一安装在&#x2F;export&#x2F;server&#x2F;anaconda3下； （3）等待执行完毕后，在新的[yes|no]选择界面选择yes；随后exit退出重新登录即可看到base，代表着安装完成； （4）创建虚拟环境pyspark，基于Python 3.8； （5）切换到虚拟环境内； （6）在虚拟环境内安装我们所需要的基本的一些包； 以上就是Anaconda的安装；Spark安装（1）上传Spark安装包到&#x2F;export&#x2F;server&#x2F;目录下；（2）使用cd命令进入到&#x2F;export&#x2F;server&#x2F;下，随后解压Spark包； （3）进入到&#x2F;etc&#x2F;profile&#x2F;中配置环境变量，添加以下内容 （4）编辑.bashrc文件，添加java和pyspark的Home值； （5）重新加载我们所添加的环境变量； （6）进入到&#x2F;export&#x2F;server&#x2F;pyspark&#x2F;bin目录下，运行.&#x2F;pyspark； 测试运行基于python的spark解释器环境 （7）通过查看4040端口得知它的运行状况。 六、Spark(stand-alone)模式stand-alone集群模式中，Spark的各个角色以独立进程的形式存在，并组成Spark集群环境，运行在Linux系统上StandAlone集群在进程上主要有三类●主节点Master进程：Master角色，管理整个集群资源，并托管各个任务的Driver●从节点Workers：Worker角色，管理每个机器的资源，分配对应资源来运行Executor（Task）●历史服务器HistoryServer：在Spark Application运行完成以后，保存事件日志数据至HDFS三台虚拟机安装Anaconda参考Spark（local）模式下的Anaconda的安装文档，在node2、node3完成对Anaconda的安装Spark（stand-alone）新配置（1）在node1节点上进入到&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf目录下；（2）将workers.template文件改名为workers； （3）修改workers内容，将localhost删除，在文本末添加以下内容； （4）将spark-env.sh.template文件改名为spark-env.sh； （5）在spar-env.sh文件末添加以下内容； （6）开启hadoop服务； （7）在HDFS上创建程序运行历史记录存放文件夹，已存在会显示File exists； （8）重新进入到&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf&#x2F;目录下，将spark-defaults.conf.template 文件改为spark-defaults.conf； （9）编辑spark-defaults.conf文件，修改添加以下内容； （10）将log4j.properties.template文件改为log4j.properties； （11）更改log4j.properties文件中的内容，将原本的INFO改为WARN； （12）将在node1上进行的操作分发各node2、node3； （13）在node2、node3上分别对分发的spark-3.1.2-bin-hadoop3.2进行软链接，软链接为spark；（14）启动历史服务器； （15）进入到18080端口，访问WebUI界面，查看所运行过的历史服务； （16）启动master和worker; （17）通过jps查看进程是否开启master和worker进程 （18）进入到8080端口，访问WebUI界面 七、Spark(HA)模式Spark Standalone集群是Master-Slaves架构的集群模式,和大部分的Master-Slaves结构集群一样,存在着Master 单点故障(SPOF)的问题；Master故障后，集群就不可用。在HA模式下当Active的Master出现故障时,另外的一个Standby Master会被选举出来。 更改Spark配置（1）在虚拟机node1上进入到&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf&#x2F;目录下； （2）进入到spark-env.sh中，删除SPARK_MASTER_HOST&#x3D;node1，随后在文本末添加如下内容； （3）分发更改的文件到虚拟机node2、node3上 （4）在node1上启动zookeeper，（注：这里所需要的zookeeper版本是3.7，非此版本的zookeeper需要更新zookeeper） （5）启动master和worker进程 （6）通过jps查看3台主机所需要的进程是否开启； （7）访问WebUI界面，查看node1和node2的状态，可以看到node1的状态为ALIVE，node2状态为STANDBY （8）删除掉node1上master的16551进程号，jps查看端口是否删除； （9）刷新node2WebUI界面，发现其状态由STANDBY变为ALIVE； 八、Spark(Yarn)模式在已有YARN集群的前提下在单独准备Spark StandAlone集群,对资源的利用就不高.Spark On YARN, 无需部署Spark集群, 只要找一台服务器, 充当Spark的客户端Spark在YARN上的角色●Master角色由YARN的ResourceManager担任●Worker角色由YARN的NodeManager担任.●Driver角色运行在YARN容器内或提交任务的客户端进程中●Executor运行在YARN提供的容器内配置Spark（1）查看&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf&#x2F;下的spark-env.sh文件，查看是否配置变量，若未配置则在文末添加内容； （2）在YARN上运行spark； （3）上述表明可以在YARN集群上运行spark；（4）client 模式测试； （5）cluster 模式测试 （6）为了查看他的运行情况，需要开启hadoop的历史服务； （7）访问WebUI界面，查看client模式下的运行状况 （8）访问WebUI界面，查看cluster模式下的运行状况 参考资料","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2022-05-15T04:14:53.961Z","updated":"2022-05-15T04:14:53.961Z","comments":true,"path":"2022/05/15/hello-world/","link":"","permalink":"http://example.com/2022/05/15/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[],"tags":[]}