<!DOCTYPE html>
<html lang=en>
<head>
    <meta charset="utf-8">
    
    <title>Spark流程配置 | Hexo</title>
    
    
        <meta name="keywords" content="Spark流程配置" />
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="五、Spark(local)模式Spark（local）本地模式是以一个独立的进程，通过其内部的多个线程来模拟整个Spark运行时的环境Spark由四类角色组成整个Spark的运行环境●Master角色，管理整个集群的资源●Worker角色，管理单个服务器的资源●Driver角色，管理单个Spark任务在运行的时候的工作●Executor角色，单个任务运行的时候的工作者 Anaconda On L">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark流程配置">
<meta property="og:url" content="http://example.com/2022/05/28/Spark%E6%B5%81%E7%A8%8B%E9%85%8D%E7%BD%AE/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="五、Spark(local)模式Spark（local）本地模式是以一个独立的进程，通过其内部的多个线程来模拟整个Spark运行时的环境Spark由四类角色组成整个Spark的运行环境●Master角色，管理整个集群的资源●Worker角色，管理单个服务器的资源●Driver角色，管理单个Spark任务在运行的时候的工作●Executor角色，单个任务运行的时候的工作者 Anaconda On L">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-05-28T07:57:22.000Z">
<meta property="article:modified_time" content="2022-05-28T08:18:09.653Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
    

    
        <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml" />
    

    
        <link rel="icon" href="/favicon.ico" />
    

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/libs/open-sans/styles.css">

    
<link rel="stylesheet" href="/libs/source-code-pro/styles.css">


    
<link rel="stylesheet" href="/css/style.css">

    
<script src="/libs/jquery/2.1.3/jquery.min.js"></script>

    
<script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script>

    
    
        
<link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">

    
    
        
<link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">

    
    
    
    


    
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
<meta name="generator" content="Hexo 6.2.0"></head>

<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">Hexo</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/">首页</a>
                
                    <a class="main-nav-link" href="/archives">归档</a>
                
                    <a class="main-nav-link" href="/categories">分类</a>
                
                    <a class="main-nav-link" href="/tags">标签</a>
                
                    <a class="main-nav-link" href="/about">关于</a>
                
            </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="Type something..." />
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>

<script src="/js/insight.js"></script>


</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/">首页</a></td>
                
                    <td><a class="main-nav-link" href="/archives">归档</a></td>
                
                    <td><a class="main-nav-link" href="/categories">分类</a></td>
                
                    <td><a class="main-nav-link" href="/tags">标签</a></td>
                
                    <td><a class="main-nav-link" href="/about">关于</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="Search" />
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
            
                <aside id="sidebar">
   
        
    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>
            
            <section id="main"><article id="post-Spark流程配置" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
                    <div class="article-meta">
                        
                        
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2022/05/28/Spark%E6%B5%81%E7%A8%8B%E9%85%8D%E7%BD%AE/">
            <time datetime="2022-05-28T07:57:22.000Z" itemprop="datePublished">2022-05-28</time>
        </a>
    </div>


                        
                            <i class="fa fa-bar-chart"></i>
                            <span id="busuanzi_container_site_pv"><span id="busuanzi_value_page_pv"></span></span>    
                        
                        
                            <div class="article-meta-button">
                                <a target="_blank" rel="noopener" href='https://github.com/zthxxx/Wiki-site/raw/writing/source/_posts/Spark流程配置.md'> Source </a>
                            </div>
                            <div class="article-meta-button">
                                <a target="_blank" rel="noopener" href='https://github.com/zthxxx/Wiki-site/edit/writing/source/_posts/Spark流程配置.md'> Edit </a>
                            </div>
                            <div class="article-meta-button">
                                <a target="_blank" rel="noopener" href='https://github.com/zthxxx/Wiki-site/commits/writing/source/_posts/Spark流程配置.md'> History </a>
                            </div>
                        
                    </div>
                
                
    
        <h1 class="article-title" itemprop="name">
            Spark流程配置
        </h1>
    

            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
        
            
                <div id="toc" class="toc-article">
                <strong class="toc-title">Catalogue</strong>
                    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99"><span class="toc-number">1.</span> <span class="toc-text">参考资料</span></a></li></ol>
                </div>
            
        
        
            <p>五、Spark(local)模式<br>Spark（local）本地模式是以一个独立的进程，通过其内部的多个线程来模拟整个Spark运行时的环境<br>Spark由四类角色组成整个Spark的运行环境<br>●Master角色，管理整个集群的资源<br>●Worker角色，管理单个服务器的资源<br>●Driver角色，管理单个Spark任务在运行的时候的工作<br>●Executor角色，单个任务运行的时候的工作者</p>
<p>Anaconda On Linux 安装<br>（1）上传Anaconda3-2021.05-Linux-x86_64.sh文件到虚拟机&#x2F;export&#x2F;server&#x2F;目录下；<br>使用cd命令进入到&#x2F;export&#x2F;server&#x2F;下，随后sh执行Anaconda3-2021.05-Linux-x86_64.sh</p>
<p>在遇到Do you accept the license terms? [yes | no]时，选择yes</p>
<p>（2）在上述命令回车后，会让你选择你想要安装的路径，统一安装在&#x2F;export&#x2F;server&#x2F;anaconda3下；</p>
<p>（3）等待执行完毕后，在新的[yes|no]选择界面选择yes；<br>随后exit退出重新登录即可看到base，代表着安装完成；</p>
<p>（4）创建虚拟环境pyspark，基于Python 3.8；</p>
<p>（5）切换到虚拟环境内；</p>
<p>（6）在虚拟环境内安装我们所需要的基本的一些包；</p>
<p>以上就是Anaconda的安装；<br>Spark安装<br>（1）上传Spark安装包到&#x2F;export&#x2F;server&#x2F;目录下；<br>（2）使用cd命令进入到&#x2F;export&#x2F;server&#x2F;下，随后解压Spark包；</p>
<p>（3）进入到&#x2F;etc&#x2F;profile&#x2F;中配置环境变量，添加以下内容</p>
<p>（4）编辑.bashrc文件，添加java和pyspark的Home值；</p>
<p>（5）重新加载我们所添加的环境变量；</p>
<p>（6）进入到&#x2F;export&#x2F;server&#x2F;pyspark&#x2F;bin目录下，运行.&#x2F;pyspark；</p>
<p>测试运行基于python的spark解释器环境</p>
<p>（7）通过查看4040端口得知它的运行状况。</p>
<p>六、Spark(stand-alone)模式<br>stand-alone集群模式中，Spark的各个角色以独立进程的形式存在，并组成Spark集群环境，运行在Linux系统上<br>StandAlone集群在进程上主要有三类<br>●主节点Master进程：Master角色，管理整个集群资源，并托管各个任务的Driver<br>●从节点Workers：Worker角色，管理每个机器的资源，分配对应资源来运行Executor（Task）<br>●历史服务器HistoryServer：在Spark Application运行完成以后，保存事件日志数据至HDFS<br>三台虚拟机安装Anaconda<br>参考Spark（local）模式下的Anaconda的安装文档，在node2、node3完成对Anaconda的安装<br>Spark（stand-alone）新配置<br>（1）在node1节点上进入到&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf目录下；<br>（2）将workers.template文件改名为workers；</p>
<p>（3）修改workers内容，将localhost删除，在文本末添加以下内容；</p>
<p>（4）将spark-env.sh.template文件改名为spark-env.sh；</p>
<p>（5）在spar-env.sh文件末添加以下内容；</p>
<p>（6）开启hadoop服务；</p>
<p>（7）在HDFS上创建程序运行历史记录存放文件夹，已存在会显示File exists；</p>
<p>（8）重新进入到&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf&#x2F;目录下，将spark-defaults.conf.template 文件改为spark-defaults.conf；</p>
<p>（9）编辑spark-defaults.conf文件，修改添加以下内容；</p>
<p>（10）将log4j.properties.template文件改为log4j.properties；</p>
<p>（11）更改log4j.properties文件中的内容，将原本的INFO改为WARN；</p>
<p>（12）将在node1上进行的操作分发各node2、node3；</p>
<p>（13）在node2、node3上分别对分发的spark-3.1.2-bin-hadoop3.2进行软链接，软链接为spark；<br>（14）启动历史服务器；</p>
<p>（15）进入到18080端口，访问WebUI界面，查看所运行过的历史服务；</p>
<p>（16）启动master和worker;</p>
<p>（17）通过jps查看进程是否开启master和worker进程</p>
<p>（18）进入到8080端口，访问WebUI界面</p>
<p>七、Spark(HA)模式<br>Spark Standalone集群是Master-Slaves架构的集群模式,和大部分的Master-Slaves结构集群一样,存在着Master 单点故障(SPOF)的问题；Master故障后，集群就不可用。在HA模式下当Active的Master出现故障时,另外的一个Standby Master会被选举出来。</p>
<p>更改Spark配置<br>（1）在虚拟机node1上进入到&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf&#x2F;目录下；</p>
<p>（2）进入到spark-env.sh中，删除SPARK_MASTER_HOST&#x3D;node1，随后在文本末添加如下内容；</p>
<p>（3）分发更改的文件到虚拟机node2、node3上</p>
<p>（4）在node1上启动zookeeper，（注：这里所需要的zookeeper版本是3.7，非此版本的zookeeper需要更新zookeeper）</p>
<p>（5）启动master和worker进程</p>
<p>（6）通过jps查看3台主机所需要的进程是否开启；</p>
<p>（7）访问WebUI界面，查看node1和node2的状态，可以看到node1的状态为ALIVE，node2状态为STANDBY</p>
<p>（8）删除掉node1上master的16551进程号，jps查看端口是否删除；</p>
<p>（9）刷新node2WebUI界面，发现其状态由STANDBY变为ALIVE；</p>
<p>八、Spark(Yarn)模式<br>在已有YARN集群的前提下在单独准备Spark StandAlone集群,对资源的利用就不高.Spark On YARN, 无需部署Spark集群, 只要找一台服务器, 充当Spark的客户端<br>Spark在YARN上的角色<br>●Master角色由YARN的ResourceManager担任<br>●Worker角色由YARN的NodeManager担任.<br>●Driver角色运行在YARN容器内或提交任务的客户端进程中<br>●Executor运行在YARN提供的容器内<br>配置Spark<br>（1）查看&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf&#x2F;下的spark-env.sh文件，查看是否配置变量，若未配置则在文末添加内容；</p>
<p>（2）在YARN上运行spark；</p>
<p>（3）上述表明可以在YARN集群上运行spark；<br>（4）client 模式测试；</p>
<p>（5）cluster 模式测试 </p>
<p>（6）为了查看他的运行情况，需要开启hadoop的历史服务；</p>
<p>（7）访问WebUI界面，查看client模式下的运行状况</p>
<p>（8）访问WebUI界面，查看cluster模式下的运行状况</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote>
<ul>
<li><a href=""></a></li>
<li><a href=""></a></li>
</ul>
</blockquote>

            </div>
        
        <footer class="article-footer">
        </footer>
    </div>
</article>


    
<nav id="article-nav">
    
    
        <a href="/2022/05/15/hello-world/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">Older</strong>
            <div class="article-nav-title">Hello World</div>
        </a>
    
</nav>





    
    




<!-- baidu url auto push script -->
<script type="text/javascript">
    !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=window.location.href,o=document.referrer;if(!e.test(r)){var n="//api.share.baidu.com/s.gif";o?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var t=new Image;t.src=n}}(window);
</script>     
</section>
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            John Doe &copy; 2022 
            <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png" /></a>
            <br> Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme - <a target="_blank" rel="noopener" href="https://github.com/zthxxx/hexo-theme-Wikitten">wikitten</a>
            
                <br>
                <span id="busuanzi_container_site_pv"><i class="fa fa-eye"></i> <span id="busuanzi_value_site_pv"></span></span>
                &nbsp;|&nbsp;
                <span id="busuanzi_container_site_pv"><i class="fa fa-user"></i> <span id="busuanzi_value_site_uv"></span></span>
            
        </div>
    </div>
</footer>

        

    
        
<script src="/libs/lightgallery/js/lightgallery.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-pager.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-zoom.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-hash.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-share.min.js"></script>

        
<script src="/libs/lightgallery/js/lg-video.min.js"></script>

    
    
        
<script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>

    
    
        <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                  autoNumber: 'AMS'
                }
            }
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    



<!-- Custom Scripts -->

<script src="/js/main.js"></script>


    </div>
</body>
</html>