<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2022-05-28T08:18:09.653Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Spark流程配置</title>
    <link href="http://example.com/2022/05/28/Spark%E6%B5%81%E7%A8%8B%E9%85%8D%E7%BD%AE/"/>
    <id>http://example.com/2022/05/28/Spark%E6%B5%81%E7%A8%8B%E9%85%8D%E7%BD%AE/</id>
    <published>2022-05-28T07:57:22.000Z</published>
    <updated>2022-05-28T08:18:09.653Z</updated>
    
    <content type="html"><![CDATA[<p>五、Spark(local)模式<br>Spark（local）本地模式是以一个独立的进程，通过其内部的多个线程来模拟整个Spark运行时的环境<br>Spark由四类角色组成整个Spark的运行环境<br>●Master角色，管理整个集群的资源<br>●Worker角色，管理单个服务器的资源<br>●Driver角色，管理单个Spark任务在运行的时候的工作<br>●Executor角色，单个任务运行的时候的工作者</p><p>Anaconda On Linux 安装<br>（1）上传Anaconda3-2021.05-Linux-x86_64.sh文件到虚拟机&#x2F;export&#x2F;server&#x2F;目录下；<br>使用cd命令进入到&#x2F;export&#x2F;server&#x2F;下，随后sh执行Anaconda3-2021.05-Linux-x86_64.sh</p><p>在遇到Do you accept the license terms? [yes | no]时，选择yes</p><p>（2）在上述命令回车后，会让你选择你想要安装的路径，统一安装在&#x2F;export&#x2F;server&#x2F;anaconda3下；</p><p>（3）等待执行完毕后，在新的[yes|no]选择界面选择yes；<br>随后exit退出重新登录即可看到base，代表着安装完成；</p><p>（4）创建虚拟环境pyspark，基于Python 3.8；</p><p>（5）切换到虚拟环境内；</p><p>（6）在虚拟环境内安装我们所需要的基本的一些包；</p><p>以上就是Anaconda的安装；<br>Spark安装<br>（1）上传Spark安装包到&#x2F;export&#x2F;server&#x2F;目录下；<br>（2）使用cd命令进入到&#x2F;export&#x2F;server&#x2F;下，随后解压Spark包；</p><p>（3）进入到&#x2F;etc&#x2F;profile&#x2F;中配置环境变量，添加以下内容</p><p>（4）编辑.bashrc文件，添加java和pyspark的Home值；</p><p>（5）重新加载我们所添加的环境变量；</p><p>（6）进入到&#x2F;export&#x2F;server&#x2F;pyspark&#x2F;bin目录下，运行.&#x2F;pyspark；</p><p>测试运行基于python的spark解释器环境</p><p>（7）通过查看4040端口得知它的运行状况。</p><p>六、Spark(stand-alone)模式<br>stand-alone集群模式中，Spark的各个角色以独立进程的形式存在，并组成Spark集群环境，运行在Linux系统上<br>StandAlone集群在进程上主要有三类<br>●主节点Master进程：Master角色，管理整个集群资源，并托管各个任务的Driver<br>●从节点Workers：Worker角色，管理每个机器的资源，分配对应资源来运行Executor（Task）<br>●历史服务器HistoryServer：在Spark Application运行完成以后，保存事件日志数据至HDFS<br>三台虚拟机安装Anaconda<br>参考Spark（local）模式下的Anaconda的安装文档，在node2、node3完成对Anaconda的安装<br>Spark（stand-alone）新配置<br>（1）在node1节点上进入到&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf目录下；<br>（2）将workers.template文件改名为workers；</p><p>（3）修改workers内容，将localhost删除，在文本末添加以下内容；</p><p>（4）将spark-env.sh.template文件改名为spark-env.sh；</p><p>（5）在spar-env.sh文件末添加以下内容；</p><p>（6）开启hadoop服务；</p><p>（7）在HDFS上创建程序运行历史记录存放文件夹，已存在会显示File exists；</p><p>（8）重新进入到&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf&#x2F;目录下，将spark-defaults.conf.template 文件改为spark-defaults.conf；</p><p>（9）编辑spark-defaults.conf文件，修改添加以下内容；</p><p>（10）将log4j.properties.template文件改为log4j.properties；</p><p>（11）更改log4j.properties文件中的内容，将原本的INFO改为WARN；</p><p>（12）将在node1上进行的操作分发各node2、node3；</p><p>（13）在node2、node3上分别对分发的spark-3.1.2-bin-hadoop3.2进行软链接，软链接为spark；<br>（14）启动历史服务器；</p><p>（15）进入到18080端口，访问WebUI界面，查看所运行过的历史服务；</p><p>（16）启动master和worker;</p><p>（17）通过jps查看进程是否开启master和worker进程</p><p>（18）进入到8080端口，访问WebUI界面</p><p>七、Spark(HA)模式<br>Spark Standalone集群是Master-Slaves架构的集群模式,和大部分的Master-Slaves结构集群一样,存在着Master 单点故障(SPOF)的问题；Master故障后，集群就不可用。在HA模式下当Active的Master出现故障时,另外的一个Standby Master会被选举出来。</p><p>更改Spark配置<br>（1）在虚拟机node1上进入到&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf&#x2F;目录下；</p><p>（2）进入到spark-env.sh中，删除SPARK_MASTER_HOST&#x3D;node1，随后在文本末添加如下内容；</p><p>（3）分发更改的文件到虚拟机node2、node3上</p><p>（4）在node1上启动zookeeper，（注：这里所需要的zookeeper版本是3.7，非此版本的zookeeper需要更新zookeeper）</p><p>（5）启动master和worker进程</p><p>（6）通过jps查看3台主机所需要的进程是否开启；</p><p>（7）访问WebUI界面，查看node1和node2的状态，可以看到node1的状态为ALIVE，node2状态为STANDBY</p><p>（8）删除掉node1上master的16551进程号，jps查看端口是否删除；</p><p>（9）刷新node2WebUI界面，发现其状态由STANDBY变为ALIVE；</p><p>八、Spark(Yarn)模式<br>在已有YARN集群的前提下在单独准备Spark StandAlone集群,对资源的利用就不高.Spark On YARN, 无需部署Spark集群, 只要找一台服务器, 充当Spark的客户端<br>Spark在YARN上的角色<br>●Master角色由YARN的ResourceManager担任<br>●Worker角色由YARN的NodeManager担任.<br>●Driver角色运行在YARN容器内或提交任务的客户端进程中<br>●Executor运行在YARN提供的容器内<br>配置Spark<br>（1）查看&#x2F;export&#x2F;server&#x2F;spark&#x2F;conf&#x2F;下的spark-env.sh文件，查看是否配置变量，若未配置则在文末添加内容；</p><p>（2）在YARN上运行spark；</p><p>（3）上述表明可以在YARN集群上运行spark；<br>（4）client 模式测试；</p><p>（5）cluster 模式测试 </p><p>（6）为了查看他的运行情况，需要开启hadoop的历史服务；</p><p>（7）访问WebUI界面，查看client模式下的运行状况</p><p>（8）访问WebUI界面，查看cluster模式下的运行状况</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><blockquote><ul><li><a href=""></a></li><li><a href=""></a></li></ul></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;五、Spark(local)模式&lt;br&gt;Spark（local）本地模式是以一个独立的进程，通过其内部的多个线程来模拟整个Spark运行时的环境&lt;br&gt;Spark由四类角色组成整个Spark的运行环境&lt;br&gt;●Master角色，管理整个集群的资源&lt;br&gt;●Worker角色，</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://example.com/2022/05/15/hello-world/"/>
    <id>http://example.com/2022/05/15/hello-world/</id>
    <published>2022-05-15T04:14:53.961Z</published>
    <updated>2022-05-15T04:14:53.961Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
</feed>
